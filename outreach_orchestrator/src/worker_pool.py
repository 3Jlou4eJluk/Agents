"""
Worker Pool - parallel processing with classification and letter generation.
"""

import asyncio
import os
import json
from pathlib import Path
from typing import Dict, Any, Optional
from langchain_openai import ChatOpenAI

# Import from local modules (duplicated functionality)
from .classification import classify_single_lead
from .agent_wrapper import SimplePlanMCPAgent, load_mcp_config_from_file, MCPClientManager


class WorkerPool:
    """
    Manages parallel workers for lead processing.
    Each worker runs two stages:
    1. Cold-outreach classification
    2. Plan-MCP letter generation (if stage 1 = relevant)
    """

    def __init__(
        self,
        num_workers: int,
        context: Dict[str, str],
        mcp_config_path: Optional[str] = None
    ):
        """
        Initialize worker pool.

        Args:
            num_workers: Number of parallel workers
            context: Loaded context (GTM, guides, instruction)
            mcp_config_path: Path to MCP config
        """
        self.num_workers = num_workers
        self.context = context
        # Use local MCP config by default
        project_root = Path(__file__).parent.parent
        self.mcp_config_path = mcp_config_path or str(project_root / "mcp_config.json")

        # Initialize semaphore for rate limiting
        self.semaphore = asyncio.Semaphore(num_workers)

        # Shared MCP client manager (one for all workers, initialized once)
        self.mcp_manager = None

        # Statistics
        self.stats = {
            'processed': 0,
            'stage1_relevant': 0,
            'stage1_not_relevant': 0,
            'stage2_letters': 0,
            'stage2_rejected': 0,
            'errors': 0
        }

    async def initialize_mcp(self):
        """Initialize shared MCP manager (call once before processing)."""
        if self.mcp_manager is not None:
            return  # Already initialized

        # Load MCP config
        try:
            mcp_config = load_mcp_config_from_file(self.mcp_config_path)
        except Exception as e:
            print(f"âš  Could not load MCP config: {e}")
            mcp_config = {}

        # Create and initialize shared MCP manager
        self.mcp_manager = MCPClientManager(mcp_config)
        await self.mcp_manager.initialize()
        print(f"âœ“ Initialized shared MCP manager with {len(await self.mcp_manager.get_tools())} tools")

    async def close_mcp(self):
        """Close shared MCP manager (call once after all processing)."""
        if self.mcp_manager is not None:
            print("ðŸ”„ Closing MCP servers...")
            await self.mcp_manager.close()
            self.mcp_manager = None

    async def process_lead(self, task: Dict[str, Any], worker_id: str) -> Dict[str, Any]:
        """
        Process a single lead through both stages.

        Args:
            task: Task dictionary from queue
            worker_id: Worker identifier

        Returns:
            Result dictionary
        """
        async with self.semaphore:
            lead_data = task['lead_data']

            try:
                print(f"\n[Worker-{worker_id}] Processing: {task['email']}")

                # STAGE 1: Classification
                stage1_result = await self._stage1_classify(lead_data)

                if not stage1_result.get('relevant'):
                    print(f"[Worker-{worker_id}] âœ— Not relevant (Stage 1): {stage1_result.get('reason', 'N/A')[:80]}")
                    self.stats['stage1_not_relevant'] += 1
                    self.stats['processed'] += 1

                    return {
                        'stage1_result': stage1_result,
                        'stage2_result': None,
                        'status': 'completed'
                    }

                print(f"[Worker-{worker_id}] âœ“ Relevant (Stage 1): {stage1_result.get('reason', 'N/A')[:80]}")
                self.stats['stage1_relevant'] += 1

                # STAGE 2: Letter Generation
                print(f"[Worker-{worker_id}] ðŸ”§ Generating letter (Stage 2)...")
                stage2_result = await self._stage2_generate_letter(task, self.context)

                if stage2_result.get('rejected'):
                    print(f"[Worker-{worker_id}] âœ— Rejected (Stage 2): {stage2_result.get('reason', 'N/A')[:80]}")
                    self.stats['stage2_rejected'] += 1
                else:
                    print(f"[Worker-{worker_id}] âœ“ Letter generated!")
                    self.stats['stage2_letters'] += 1

                self.stats['processed'] += 1

                return {
                    'stage1_result': stage1_result,
                    'stage2_result': stage2_result,
                    'status': 'completed'
                }

            except Exception as e:
                print(f"[Worker-{worker_id}] âš  Error: {str(e)}")
                self.stats['errors'] += 1
                self.stats['processed'] += 1

                return {
                    'stage1_result': None,
                    'stage2_result': None,
                    'status': 'failed',
                    'error': str(e)
                }

    async def _stage1_classify(self, lead_data: Dict) -> Dict:
        """
        Stage 1: Classify lead using cold-outreach-agent.

        Args:
            lead_data: Lead data dictionary

        Returns:
            Classification result: {relevant: bool, reason: str}
        """
        # Initialize DeepSeek for classification
        classification_model = os.getenv("DEEPSEEK_CLASSIFICATION_MODEL", "deepseek-chat")
        llm = ChatOpenAI(
            model=classification_model,
            temperature=0,
            base_url="https://api.deepseek.com",
            api_key=os.getenv("DEEPSEEK_API_KEY"),
            model_kwargs={"response_format": {"type": "json_object"}}
        )

        # Prepare lead for classification
        lead = {
            'email': lead_data.get('Email') or lead_data.get('email'),
            'name': (lead_data.get('First Name', '') + ' ' + lead_data.get('Last Name', '')).strip() or lead_data.get('name'),
            'company': lead_data.get('companyName') or lead_data.get('company'),
            'job_title': lead_data.get('jobTitle') or lead_data.get('job_title'),
            'linkedin_url': lead_data.get('linkedIn') or lead_data.get('linkedin_url'),
            'raw_data': lead_data,
            'enriched_data': {}  # Will be enriched by Stage 2 if needed
        }

        # Run classification with GTM context
        gtm_context = self.context.get('gtm', '')
        result = await classify_single_lead(lead, llm, gtm_context)

        if result['error']:
            raise Exception(result['error'])

        return result['classification']

    async def _stage2_generate_letter(self, task: Dict, context: Dict) -> Dict:
        """
        Stage 2: Generate letter using plan_mcp_agent.

        Args:
            task: Task with lead data
            context: Agent context (GTM, guides, instruction)

        Returns:
            Letter generation result
        """
        if self.mcp_manager is None:
            return {
                'rejected': True,
                'reason': 'MCP manager not initialized',
                'letter': None
            }

        lead_data = task['lead_data']
        linkedin_url = task['linkedin_url']

        # Format task
        task_text = self._format_agent_task(lead_data, linkedin_url, context)

        # Create agent with shared MCP manager
        agent = SimplePlanMCPAgent(
            model="deepseek:deepseek-chat",
            max_iterations=30,
            shared_mcp_manager=self.mcp_manager  # Reuse shared MCP manager!
        )

        try:
            # Initialize agent (won't re-initialize MCP)
            await agent.initialize()

            # Run agent with the task
            result = await agent.run(task_text)

            # Extract result from agent output
            final_result = result.get('final_result', '')

            # Extract JSON from text (LLMs often add extra text around JSON)
            letter_result = self._extract_json_from_text(final_result)

            if not letter_result:
                # Fallback if no JSON found
                return {
                    'rejected': True,
                    'reason': 'Failed to parse agent response',
                    'letter': None,
                    'relevance_assessment': 'ERROR',
                    'notes': f'Raw response: {final_result[:200]}...'
                }

            return letter_result

        finally:
            # Always close agent
            await agent.close()

    def _extract_json_from_text(self, text: str) -> Optional[Dict]:
        """
        Extract JSON from text that may contain markdown or extra content.

        Args:
            text: Text that may contain JSON

        Returns:
            Parsed JSON dict or None
        """
        import re

        # Try 1: Find JSON in markdown code block ```json ... ```
        json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', text, re.DOTALL)
        if json_match:
            try:
                return json.loads(json_match.group(1))
            except json.JSONDecodeError:
                pass

        # Try 2: Find JSON object anywhere in text
        json_match = re.search(r'\{[^{}]*"rejected"[^{}]*\}', text, re.DOTALL)
        if json_match:
            try:
                # Find the full JSON object (handle nested braces)
                start = json_match.start()
                brace_count = 0
                end = start
                for i, char in enumerate(text[start:], start=start):
                    if char == '{':
                        brace_count += 1
                    elif char == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            end = i + 1
                            break

                json_str = text[start:end]
                return json.loads(json_str)
            except json.JSONDecodeError:
                pass

        # Try 3: Parse entire text as JSON
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            pass

        return None

    def _format_agent_task(self, lead_data: Dict, linkedin_url: str, context: Dict) -> str:
        """
        Format task for plan_mcp_agent.

        Args:
            lead_data: Lead data
            linkedin_url: LinkedIn URL
            context: Context dictionary

        Returns:
            Formatted task string
        """
        name = (lead_data.get('First Name', '') + ' ' + lead_data.get('Last Name', '')).strip() or lead_data.get('name', 'N/A')
        company = lead_data.get('companyName') or lead_data.get('company', 'N/A')
        job_title = lead_data.get('jobTitle') or lead_data.get('job_title', 'N/A')

        return f"""
# Task: Cold Outreach Letter Generation

## Lead Information
- **Name:** {name}
- **Company:** {company}
- **Job Title:** {job_title}
- **LinkedIn:** {linkedin_url}

## Instructions - ÐŸÐ¾Ñ€ÑÐ´Ð¾Ðº Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ð¹

**Ð¨ÐÐ“ 1: Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ sequential_thinking Ð´Ð»Ñ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ**
- Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð·Ð¾Ð²Ð¸ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚ `sequentialthinking` Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ñ€Ð°ÑÐ¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ€Ð°Ð±Ð¾Ñ‚Ñƒ

**Ð¨ÐÐ“ 2: Ð“Ð›Ð£Ð‘ÐžÐšÐžÐ• Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ LinkedIn**
- Ð˜Ð·ÑƒÑ‡Ð¸ LinkedIn Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÑŒ **ÐžÐ‘Ð¯Ð—ÐÐ¢Ð•Ð›Ð¬ÐÐž Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑ bright_data**
- LINKEDIN URL: {linkedin_url}
- âš ï¸ **Ð’ÐÐ–ÐÐž: bright_data Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¢ÐžÐ›Ð¬ÐšÐž Ð´Ð»Ñ LinkedIn, Ð½Ð¸ Ð´Ð»Ñ Ñ‡ÐµÐ³Ð¾ Ð±Ð¾Ð»ÑŒÑˆÐµ!**

**RETRY Ð›ÐžÐ“Ð˜ÐšÐ Ð´Ð»Ñ bright_data:**
1. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ bright_data Ð´Ð»Ñ LinkedIn
2. Ð•ÑÐ»Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð» Ð¾ÑˆÐ¸Ð±ÐºÑƒ Ð¸Ð»Ð¸ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ â†’ **ÐžÐ‘Ð¯Ð—ÐÐ¢Ð•Ð›Ð¬ÐÐž Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ bright_data Ð•Ð©Ð Ð ÐÐ—**
3. Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ð¾ÑÐ»Ðµ 2-Ñ… Ð½ÐµÑƒÐ´Ð°Ñ‡Ð½Ñ‹Ñ… Ð¿Ð¾Ð¿Ñ‹Ñ‚Ð¾Ðº Ð¼Ð¾Ð¶ÐµÑˆÑŒ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ tavily Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ° Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¾ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐºÐµ
4. Ð•ÑÐ»Ð¸ ÑÐ¾Ð²ÑÐµÐ¼ Ð½ÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… â†’ Ð¾Ñ‚ÐºÐ»Ð¾Ð½Ð¸ Ð»Ð¸Ð´Ð° Ñ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ð¾Ð¹ "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ LinkedIn"

**Ð˜Ð©Ð˜ ÐšÐžÐÐšÐ Ð•Ð¢Ð˜ÐšÐ£ Ð² LinkedIn:**
- Ð¡Ð²ÐµÐ¶Ð¸Ðµ Ð¿Ð¾ÑÑ‚Ñ‹, Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ, ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸ (Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 3-6 Ð¼ÐµÑÑÑ†ÐµÐ²)
- ÐšÐ¾Ð½Ñ„ÐµÑ€ÐµÐ½Ñ†Ð¸Ð¸, Ð²Ñ‹ÑÑ‚ÑƒÐ¿Ð»ÐµÐ½Ð¸Ñ, Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸Ð¸
- Ð¡Ð¿ÐµÑ†Ð¸Ñ„Ð¸Ñ‡Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñ‹, Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸Ñ, ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ñ Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸Ð¹
- ÐšÐ°Ñ€ÑŒÐµÑ€Ð½Ñ‹Ðµ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ, Ð¿Ñ€Ð¾Ð´Ð²Ð¸Ð¶ÐµÐ½Ð¸Ñ

**Ð¨ÐÐ“ 3: Ð“Ð›Ð£Ð‘ÐžÐšÐžÐ• Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸**
- Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ **tavily-search** Ð´Ð»Ñ Ð¸Ð·ÑƒÑ‡ÐµÐ½Ð¸Ñ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸ (ÐÐ• bright_data!)
- ÐŸÐ¾Ð¸Ñ‰Ð¸ ÑÐ²ÐµÐ¶Ð¸Ðµ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ (Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 3-6 Ð¼ÐµÑÑÑ†ÐµÐ²)
- ÐŸÑ€Ð¾Ð´ÑƒÐºÑ‚Ñ‹, ÐºÐ»Ð¸ÐµÐ½Ñ‚Ñ‹, ÐºÐµÐ¹ÑÑ‹
- ÐžÑ‚Ñ€Ð°ÑÐ»ÑŒ, ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ñ‹, Ð²Ñ‹Ð·Ð¾Ð²Ñ‹
- Ð Ð°Ð·Ð¼ÐµÑ€, ÑÑ‚Ð°Ð´Ð¸Ñ Ñ€Ð¾ÑÑ‚Ð°, funding

**Ð¨ÐÐ“ 4: ÐÐ°Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¿Ð¸ÑÑŒÐ¼Ð° - ÐšÐ Ð˜Ð¢Ð•Ð Ð˜Ð˜ ÐšÐÐ§Ð•Ð¡Ð¢Ð’Ð**

**OBSERVATION Ð´Ð¾Ð»Ð¶Ð½Ð° Ð±Ñ‹Ñ‚ÑŒ:**
- âœ… Ð¡Ð¿ÐµÑ†Ð¸Ñ„Ð¸Ñ‡Ð½Ð°Ñ Ð¸ ÑÐ²ÐµÐ¶Ð°Ñ (Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 3-6 Ð¼ÐµÑÑÑ†ÐµÐ²)
- âœ… ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ðµ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ (Ð½Ðµ "I saw you work at X")
- âŒ ÐÐ• Ð¾Ð±Ñ‰Ð¸Ðµ Ñ„Ð°ÐºÑ‚Ñ‹ ("you're a manager")

**INSIGHT Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ:**
- âœ… ÐÐµÐ¾Ñ‡ÐµÐ²Ð¸Ð´Ð½Ñ‹Ð¼ Ð¸ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð¸Ñ€ÑƒÑŽÑ‰Ð¸Ð¼ Ð³Ð»ÑƒÐ±Ð¾ÐºÐ¾Ðµ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ Ð¸Ñ… Ð²Ñ‹Ð·Ð¾Ð²Ð¾Ð²
- âœ… Ð¡Ð²ÑÐ·Ð°Ð½Ð½Ñ‹Ð¼ Ñ Ð±Ð¾Ð»ÑŒÑŽ ResolveOnce Ñ€ÐµÑˆÐ°ÐµÑ‚
- âŒ ÐÐ• Ð¿Ð¾Ð²ÐµÑ€Ñ…Ð½Ð¾ÑÑ‚Ð½Ñ‹Ð¼ ("you want to optimize processes")

**COMPANY CONTEXT:**
- âœ… ÐŸÐ¾ÐºÐ°Ð¶Ð¸ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ Ð¸Ñ… Ð±Ð¸Ð·Ð½ÐµÑÐ°, Ð¾Ñ‚Ñ€Ð°ÑÐ»Ð¸, Ð²Ñ‹Ð·Ð¾Ð²Ð¾Ð²
- âœ… Ð£Ð²ÑÐ¶Ð¸ Ñ Ð±Ð¾Ð»ÑŒÑŽ (knowledge loss, ticket resolution)

**POV Framework - Ð¡Ð¢Ð ÐžÐ“Ðž:**
- Observation (1 sentence) - ÑÐ¿ÐµÑ†Ð¸Ñ„Ð¸Ñ‡Ð½Ð°Ñ, ÑÐ²ÐµÐ¶Ð°Ñ
- Insight (2-3 sentences) - Ð³Ð»ÑƒÐ±Ð¾ÐºÐ¸Ð¹, Ð½ÐµÐ¾Ñ‡ÐµÐ²Ð¸Ð´Ð½Ñ‹Ð¹, ÑÐ²ÑÐ·ÑŒ Ñ Ð¸Ñ… Ð±Ð¾Ð»ÑŒÑŽ
- Soft question (1 sentence) - Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚Ñ‹Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ, Ð½Ðµ pushy

- ÐžÑ†ÐµÐ½Ð¸ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ Ð»Ð¸Ð´Ð° Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñƒ (ÐšÐžÐ ÐžÐ¢ÐšÐž)
- ÐŸÐ¾Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐ¹ Ð²Ñ€ÐµÐ¼Ñ Ð´Ð»Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ð¿Ð¸ÑÑŒÐ¼Ð° (Ð¿Ð¾ ÐœÐ¡Ðš)

**Ð¨ÐÐ“ 5: Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ°**
- Ð£Ð±ÐµÐ´Ð¸ÑÑŒ Ñ‡Ñ‚Ð¾ Ð²ÑÑ‘ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾ Ð´Ð»Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸

**ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐ˜ Ð’ÐÐ–ÐÐž:**
- ðŸš« **ÐÐ• Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ bright_data Ð´Ð»Ñ ÑÐ°Ð¹Ñ‚Ð¾Ð² ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¹, Ð¿Ð¾Ð¸ÑÐºÐ°, Ð¸Ð»Ð¸ Ñ‡ÐµÐ³Ð¾-Ð»Ð¸Ð±Ð¾ ÐºÑ€Ð¾Ð¼Ðµ LinkedIn!**
- ðŸš« **ÐÐ• Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ firecrawl Ð´Ð»Ñ LinkedIn - Ð¾Ð½ Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚!**
- âœ… **Ð”Ð»Ñ LinkedIn â†’ bright_data**
- âœ… **Ð”Ð»Ñ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¹/Ð¿Ð¾Ð¸ÑÐºÐ° â†’ tavily-search**
- ÐŸÐ¸ÑÑŒÐ¼Ð¾ Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ Ð½Ð° Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ
- ÐœÐµÐ½Ñ Ð·Ð¾Ð²ÑƒÑ‚ Michael (Almas - ÑÑ‚Ð¾ Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð² Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ…)
- ÐŸÐ¸ÑˆÐ¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ñ‚ÑƒÑ‚, Ð½Ðµ Ð² Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚

## Output Format

**ÐžÐ‘Ð¯Ð—ÐÐ¢Ð•Ð›Ð¬ÐÐž Ð²ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž Ð²Ð°Ð»Ð¸Ð´Ð½Ñ‹Ð¹ JSON (Ð±ÐµÐ· markdown, Ð±ÐµÐ· Ð»Ð¸ÑˆÐ½ÐµÐ³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°):**

Ð•ÑÐ»Ð¸ Ð»Ð¸Ð´ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚ÐµÐ½:
```json
{{
  "rejected": false,
  "reason": null,
  "letter": {{
    "subject": "Email subject in English",
    "body": "Email body in English (POV Framework)",
    "send_time_msk": "Tuesday, 19:00 MSK",
    "personalization_signals": ["signal 1", "signal 2", "signal 3"]
  }},
  "relevance_assessment": "BRIEF relevance assessment in Russian",
  "notes": "Any additional notes"
}}
```

Ð•ÑÐ»Ð¸ Ð»Ð¸Ð´ ÐÐ• Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚ÐµÐ½ Ð¿Ð¾ÑÐ»Ðµ Ð³Ð»ÑƒÐ±Ð¾ÐºÐ¾Ð³Ð¾ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ñ:
```json
{{
  "rejected": true,
  "reason": "Specific reason in Russian",
  "letter": null,
  "relevance_assessment": "NOT RELEVANT - brief explanation"
}}
```

---

## Project Context

{context.get('gtm', '')}

---

## Writing Guides

{context.get('guides', '')}

---

## Task Instructions

{context.get('instruction', '')}
"""

    def get_stats(self) -> Dict[str, int]:
        """Get current processing statistics."""
        return self.stats.copy()
